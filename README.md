## Задание

Модифицировать программу из [лабораторной работы №3](https://github.com/eeeeagle/PP_3) для параллельной работы по технологии CUDA.

## Исследование: зависимость времени выполнения вычислений от объема данных

В виду отсутствия GPU от Nvidia, результат параллельных вычислений на неизвестном GPU был получен от третьих лиц.

_Таблица 1: время (в секундах) выполнения операции умножения квадратных матриц N порядка по технологии CUDA_
|**N**   |**t, с** |
|:------:|:-------:|
|**500** |0.051    |
|**750** |0.158    |
|**1000**|0.353    |
|**1250**|0.775    |
|**1500**|1.194    |
|**1750**|1.786    |
|**2000**|2.523    |
|**2250**|3.527    |
|**2500**|4.792    |

_График 1: сравнение зависимости времени выполнения операции умножения матриц от объема при [последовательных](https://github.com/eeeeagle/PP_1) (синия линия) и параллельных вычислений по технологиям [OpenMP, 4 ядра](https://github.com/eeeeagle/PP_2) (красная линия), [MPI, 4 ядра](https://github.com/eeeeagle/PP_3) (зелёная линия) и CUDA (жёлтая линия)_
![lab](https://user-images.githubusercontent.com/90867530/209395727-f5fcfa4b-5ead-4948-a23d-dd9297a49d9b.png)

Параллельные вычисления по технологии CUDA многократно обгоняют последовательные вычисления и параллельные вычисления по технологии OpenMP и MPI по времени в нескольких десятоков раз, и с ростом объема задачи разрыв, вероятно, будет только увеличиватся. Таким образом, CUDA является наиболее предпочтительной технологией при обработке огромных данных, хотя применить её возомжно только на GPU от Nvidia.
